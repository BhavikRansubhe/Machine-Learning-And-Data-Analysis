{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME     : Bhavik Ransubhe\n",
    "# CLASS    : B.E (B) COMPUTER\n",
    "# ROLL No. : 41261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLDS \n",
    "### Assignment No. 2 :Recognize optical character using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "14Ct8fDjTTxg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f6c59bd2646e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loading the Data Into Memory (with Keras)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Loading the Data Into Memory (with Keras)\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtEuSzZATTxh"
   },
   "source": [
    "With the `mnist` module, we can easily load the MNIST data, already partitioned into images and labels for both training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yLceppiTTxh"
   },
   "outputs": [],
   "source": [
    "# the data, split between train and validation sets\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqrS-gZ-TTxi"
   },
   "source": [
    "## Exploring the MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZBbw4vgTTxi"
   },
   "source": [
    "We stated above that the MNIST dataset contained 70,000 grayscale images of handwritten digits. By executing the following cells, we can see that Keras has partitioned 60,000 of these images for training, and 10,000 for validation (after training), and also, that each image itself is a 2D array with the dimensions 28x28:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ_uOhxwTTxi"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLzdeDQbTTxi"
   },
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81NFbOcSTTxi"
   },
   "source": [
    "Furthermore, we can see that these 28x28 images are represented as a collection of unsigned 8-bit integer values between 0 and 255, the values corresponding with a pixel's grayscale value where `0` is black, `255` is white, and all other values are in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qo9_ju8mTTxi"
   },
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MmmxYK4TTxj"
   },
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m375TAfFTTxj"
   },
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n9KZEbMsTTxj"
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CEatlOnTTxj"
   },
   "source": [
    "Using [Matplotlib](https://matplotlib.org/), we can render one of these grayscale images in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTpPGmR7TTxj"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[0]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnD7Z4PrTTxj"
   },
   "source": [
    "In this way we can now see that this is a 28x28 pixel image of a 5. Or is it a 3? The answer is in the `y_train` data, which contains correct labels for the data. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kufN005wTTxj"
   },
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZkeifOITTxk"
   },
   "source": [
    "## Preparing the Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbNs_UpMTTxk"
   },
   "source": [
    "For this particular image classification problem, there are 3 tasks we should perform with the data in preparation for training:\n",
    "1. Flatten the image data, to simplify the image input into the model\n",
    "2. Normalize the image data, to make the image input values easier to work with for the model\n",
    "3. Categorize the labels, to make the label values easier to work with for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab9k7IT2TTxk"
   },
   "source": [
    "### Flattening the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvHfF3ozTTxk"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_valid = x_valid.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JDEVYJtTTxk"
   },
   "source": [
    "We can confirm that the image data has been reshaped and is now a collection of 1D arrays containing 784 pixel values each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPk_jO1-TTxl"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsgiHuFsTTxl"
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKVP5W_NTTxl"
   },
   "source": [
    "### Normalizing the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0uPZ34lTTxl"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IB-XweATTxl"
   },
   "source": [
    "We can now see that the values are all floating point values between `0.0` and `1.0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TG7bihXPTTxm"
   },
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBJxkbOwTTxm"
   },
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UcDXwhrETTxm"
   },
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMls8AzQTTxo"
   },
   "source": [
    "### Categorically Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lf-7Vco6TTxo"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT429ijPTTxo"
   },
   "source": [
    "Here are the first 10 values of the training labels, which you can see have now been categorically encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGH8lmU_TTxp"
   },
   "outputs": [],
   "source": [
    "y_train[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZ2NEbtvTTxp"
   },
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3IHXI_ETTxp"
   },
   "source": [
    "To begin, we will use Keras's [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model class to instantiate an instance of a model that will have a series of layers that data will pass through in sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8LM5555TTxq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjVoerAjTTxq"
   },
   "source": [
    "### Creating the Input Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7DhQgBZTTxq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLGI7tDVTTxr"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArrgNuvxTTxr"
   },
   "source": [
    "### Creating the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0_wzDBtTTxr"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdOcebQjTTxr"
   },
   "source": [
    "### Creating the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAa87Np6TTxs"
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6RMbZ92TTxs"
   },
   "source": [
    "### Summarizing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Puao9ruTTxs"
   },
   "source": [
    "Keras provides the model instance method [summary](https://www.tensorflow.org/api_docs/python/tf/summary) which will print a readable summary of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31FRqfFaTTxs"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i57hDg9ATTxs"
   },
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgNwmnzPTTxt"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WJru8EOTTxt"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrAtj7UZTTxt"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6-YNQDmTTxu"
   },
   "source": [
    "## Clear the Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYq9JCb1TTxu"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "OCR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
